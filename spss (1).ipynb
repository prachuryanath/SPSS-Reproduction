{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cdc3e7-aa8e-46b9-9551-e96dab8e4f4e",
   "metadata": {},
   "source": [
    "# Striving for Simplicity: Simple Yet Effective Prior-Aware Pseudo-Labeling for Semi-Supervised Ultrasound Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444610f-0cf9-4899-8c20-8dfc689569af",
   "metadata": {},
   "source": [
    "* Paper Code : 4867\n",
    "* Paper Link : https://papers.miccai.org/miccai-2024/735-Paper2948.html\n",
    "* Reproduction Level : 3 (25 points)\n",
    "* Github Link : https://github.com/prachuryanath/SPSS-Reproduction\n",
    "\n",
    "The paper presents a straightforward yet powerful pseudo-labeling technique for semi-supervised ultrasound image segmentation, effectively tackling the challenges of having limited labeled data and dealing with anatomical inaccuracies.\n",
    "\n",
    "Instead of relying on complex methods, the proposed encoder-twin-decoder network uses an adversarially learned shape prior to ensure the segmentations are both anatomically accurate and aligned with the ground truth. This simple approach outperforms state-of-the-art techniques on two benchmarks, offering a solid foundation for future research in semi-supervised medical image segmentation. By striking a balance between labeled and unlabeled data, the method enhances the precision and usability of automated ultrasound analysis.\n",
    "\n",
    "### By - Prachurya Nath\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/WUTCM-Lab/Shape-Prior-Semi-Seg/assets/155703366/029950f0-78a2-400a-91a4-837d8166a1cd\" width=\"750\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26789bf1-7396-4c2d-943e-defd63762ea0",
   "metadata": {},
   "source": [
    "## Hardware Comments\n",
    "* Graphics Used : A100 (40 GB)\n",
    "* Training Time GAN : 19 hrs 52 mins\n",
    "* Training Time CNN Model : 6 hrs 57 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3076a49b-5afd-4cb4-942d-b7aa7a73be31",
   "metadata": {},
   "source": [
    "## Figure to Reproduce : Fig 3\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/prachuryanath/WBC-NCA---Reproduction/refs/heads/main/images/spss_table.jpg\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d25c1-17e9-4b40-88aa-a84e9013ff60",
   "metadata": {},
   "source": [
    "### Steps to download dataset\n",
    "\n",
    "* Extract it into tn3k folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20648210-2ab2-4b2c-8ea7-a6577d7b3625",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-18 19:22:57--  https://docs.google.com/uc?export=download&confirm=&id=1reHyY5eTZ5uePXMVMzFOq5j3eFOSp50F\n",
      "Resolving docs.google.com (docs.google.com)... 2a00:1450:4001:831::200e, 142.250.184.238\n",
      "Connecting to docs.google.com (docs.google.com)|2a00:1450:4001:831::200e|:443... connected.\n",
      "HTTP request sent, awaiting response... 303 See Other\n",
      "Location: https://drive.usercontent.google.com/download?id=1reHyY5eTZ5uePXMVMzFOq5j3eFOSp50F&export=download [following]\n",
      "--2025-02-18 19:22:57--  https://drive.usercontent.google.com/download?id=1reHyY5eTZ5uePXMVMzFOq5j3eFOSp50F&export=download\n",
      "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 2a00:1450:4001:81d::2001, 216.58.206.65\n",
      "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|2a00:1450:4001:81d::2001|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2431 (2.4K) [text/html]\n",
      "Saving to: ‘thyroid.zip’\n",
      "\n",
      "thyroid.zip         100%[===================>]   2.37K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-02-18 19:22:57 (27.5 MB/s) - ‘thyroid.zip’ saved [2431/2431]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1reHyY5eTZ5uePXMVMzFOq5j3eFOSp50F' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1reHyY5eTZ5uePXMVMzFOq5j3eFOSp50F\" -O thyroid.zip && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa2d86-6cba-4a6b-928d-c7f7756b70b2",
   "metadata": {},
   "source": [
    "## Create environment and install libraries\n",
    "\n",
    "* python -m venv .spss\n",
    "* source spss/bin/activate\n",
    "* pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657434bd-51d8-4694-94b5-29d6c93510b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46009ebb-9f90-4e8d-a4ff-2ff15f271cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "import yaml\n",
    "import warnings\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from GAN.data.tn3k import tn3kDataSet\n",
    "import GAN.models.dcgan as dcgan\n",
    "import GAN.models.mlp as mlp\n",
    "import warnings\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Ignore UserWarnings to avoid clutter in output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f8f4c-7574-476c-8e63-3885359d5a5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## GAN\n",
    "\n",
    "**From the paper :** We first train a GAN leveraging existing labels. Specifically, we resize all ground truth segmentation masks into a fixed size of 64 × 64 and set batch size to 16. We optimize the generator and discriminator using two RMSprop optimizers with a learning rate of 0.00005, and the total number of epochs is set to 5,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9208773-a9a5-45e3-a978-d1199dfef464",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f2dff5-10b5-4500-a6b8-5cdd7b7fc808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(dataset='tn3k', dataroot='tn3k/', workers=2, batchSize=16, imageSize=64, nc=1, nz=100, ngf=64, ndf=64, niter=5001, lrD=5e-05, lrG=5e-05, beta1=0.5, ngpu=2, netG='', netD='', clamp_lower=-0.01, clamp_upper=0.01, Diters=5, noBN=False, mlp_G=False, mlp_D=False, n_extra_layers=0, experiment='result', adam=False, root='', expID=1)\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "with open(\"config_gan.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "from types import SimpleNamespace\n",
    "\n",
    "opt = SimpleNamespace(**config)\n",
    "print(opt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6b4955-2736-47e5-9c7c-db86617070de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5739\n"
     ]
    }
   ],
   "source": [
    "# Create result directory if not existing\n",
    "if opt.experiment is None:\n",
    "    opt.experiment = 'samples'\n",
    "os.system('mkdir {0}'.format(opt.experiment))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "opt.manualSeed = random.randint(1, 10000) # fix seed\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc0d1e3-e2ac-478b-b159-b7ef823e16ea",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd9f22ea-8395-4118-bb9b-6b5e6ff2f754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the appropriate dataset\n",
    "if opt.dataset == 'tn3k':\n",
    "    dataset = tn3kDataSet(opt.root, opt.expID, mode='train')\n",
    "assert dataset\n",
    "\n",
    "# DataLoader for batching and shuffling the dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
    "                                        shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "# Define model hyperparameters\n",
    "ngpu = int(opt.ngpu) # number of gpu #1\n",
    "nz = int(opt.nz) # size of the latent z vector #100 \n",
    "ngf = int(opt.ngf) #64\n",
    "ndf = int(opt.ndf) #64\n",
    "nc = int(opt.nc) #input images channels #3\n",
    "n_extra_layers = int(opt.n_extra_layers) #Number of extra layers on gen and disc #0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a57dc09-a3d0-40fd-b768-feec5632bf76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "# Choose Generator architecture based on options\n",
    "if opt.noBN:\n",
    "    netG = dcgan.DCGAN_G_nobn(opt.imageSize, nz, nc, ngf, ngpu, n_extra_layers)\n",
    "elif opt.mlp_G:\n",
    "    netG = mlp.MLP_G(opt.imageSize, nz, nc, ngf, ngpu)\n",
    "else:\n",
    "    netG = dcgan.DCGAN_G(opt.imageSize, nz, nc, ngf, ngpu, n_extra_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba07cb41-51b9-4373-a2a8-d02ff2e7c4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save Generator configuration to JSON\n",
    "generator_config = {\"imageSize\": opt.imageSize, \"nz\": nz, \"nc\": nc, \"ngf\": ngf, \"ngpu\": ngpu, \"n_extra_layers\": n_extra_layers, \"noBN\": opt.noBN, \"mlp_G\": opt.mlp_G}\n",
    "\n",
    "with open(os.path.join(opt.experiment, \"generator_config.json\"), 'w') as gcfg:\n",
    "    gcfg.write(json.dumps(generator_config)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a56aa1-0835-4257-9395-624d7db696fb",
   "metadata": {},
   "source": [
    "## Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da7c9f0e-1a29-465f-8362-2f284d63ddbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Generator weights\n",
    "netG.apply(weights_init)\n",
    "if opt.netG != '': # load checkpoint if needed\n",
    "    netG.load_state_dict(torch.load(opt.netG))\n",
    "\n",
    "# Choose Discriminator architecture based on options    \n",
    "if opt.mlp_D:\n",
    "    netD = mlp.MLP_D(opt.imageSize, nz, nc, ndf, ngpu)\n",
    "else:\n",
    "    netD = dcgan.DCGAN_D(opt.imageSize, nz, nc, ndf, ngpu, n_extra_layers)\n",
    "    netD.apply(weights_init)\n",
    "\n",
    "if opt.netD != '':\n",
    "    netD.load_state_dict(torch.load(opt.netD))\n",
    "\n",
    "# Setup input tensors for real and fake data\n",
    "input = torch.FloatTensor(opt.batchSize, 3, opt.imageSize, opt.imageSize)\n",
    "noise = torch.FloatTensor(opt.batchSize, nz, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8a31597-8dc0-4203-bd3e-a494e240d7aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda ===================================== \n",
      "No of cuda devices : 1\n"
     ]
    }
   ],
   "source": [
    "# Enable GPU usage if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda ===================================== \")\n",
    "    print(\"No of cuda devices :\", torch.cuda.device_count())\n",
    "    netD = nn.DataParallel(netD, device_ids=[0])\n",
    "    netD = netD.cuda(0)\n",
    "    netG = nn.DataParallel(netG, device_ids=[0])\n",
    "    netG.cuda(0)\n",
    "    input = input.cuda(0)\n",
    "    one, mone = one.cuda(0), mone.cuda(0)\n",
    "    noise, fixed_noise = noise.cuda(0), fixed_noise.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b981abd8-7c7d-4177-94f8-31d284399b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "if opt.adam:\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lrD, betas=(opt.beta1, 0.999))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lrG, betas=(opt.beta1, 0.999))\n",
    "else:\n",
    "    optimizerD = optim.RMSprop(netD.parameters(), lr = opt.lrD)\n",
    "    optimizerG = optim.RMSprop(netG.parameters(), lr = opt.lrG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2fbe66-baaa-4059-9adf-06a9fd35f1fc",
   "metadata": {},
   "source": [
    "## Training the GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd16825-1fa8-4daf-86c0-81c5a3233c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator iterations counter\n",
    "gen_iterations = 0\n",
    "for epoch in range(opt.niter):\n",
    "    data_iter = iter(dataloader)\n",
    "    i = 0\n",
    "    while i < len(dataloader):\n",
    "        # Discriminator (D) network\n",
    "        # Enable gradient computation for the discriminator parameters\n",
    "        for p in netD.parameters(): \n",
    "            p.requires_grad = True\n",
    "\n",
    "        # Set the number of discriminator iterations based on the current training step\n",
    "        if gen_iterations < 25 or gen_iterations % 500 == 0:\n",
    "            Diters = 100\n",
    "        else:\n",
    "            Diters = opt.Diters\n",
    "            \n",
    "        # Train the discriminator Diters times per generator update\n",
    "        j = 0\n",
    "        while j < Diters and i < len(dataloader):\n",
    "            j += 1\n",
    "\n",
    "            # clamp parameters to a cube\n",
    "            for p in netD.parameters():\n",
    "                p.data.clamp_(opt.clamp_lower, opt.clamp_upper)\n",
    "\n",
    "            data = next(data_iter)\n",
    "            i += 1\n",
    "\n",
    "            # train with real images\n",
    "            real = data['label']\n",
    "            real_cpu = F.interpolate(real, size=(64, 64), mode='bilinear', align_corners=False)\n",
    "            netD.zero_grad()\n",
    "            batch_size = real_cpu.size(0)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                real_cpu = real_cpu.cuda(0)\n",
    "            input.resize_as_(real_cpu).copy_(real_cpu)\n",
    "            inputv = Variable(input)\n",
    "            \n",
    "            # Compute loss for real images\n",
    "            errD_real = netD(inputv)\n",
    "            errD_real.backward(one)\n",
    "\n",
    "            # train with fake images generated by the generator\n",
    "            noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "            noisev = Variable(noise, volatile = True) # totally freeze netG\n",
    "            fake = Variable(netG(noisev).data)\n",
    "            inputv = fake\n",
    "            \n",
    "            # Compute discriminator's error for fake images\n",
    "            errD_fake = netD(inputv)\n",
    "            errD_fake.backward(mone)\n",
    "            errD = errD_real - errD_fake\n",
    "            optimizerD.step()\n",
    "            \n",
    "        # Generator (G) Network\n",
    "        for p in netD.parameters():\n",
    "            p.requires_grad = False # to avoid computation\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        # Generate new noise to feed into the generator\n",
    "        noise.resize_(opt.batchSize, nz, 1, 1).normal_(0, 1)\n",
    "        noisev = Variable(noise)\n",
    "        fake = netG(noisev)\n",
    "\n",
    "        # Compute generator's error based on discriminator's response\n",
    "        errG = netD(fake)\n",
    "        errG.backward(one)\n",
    "        optimizerG.step()\n",
    "        gen_iterations += 1\n",
    "\n",
    "        # Print loss values for the current step\n",
    "        print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, opt.niter, i, len(dataloader), gen_iterations,\n",
    "            errD.data[0], errG.data[0], errD_real.data[0], errD_fake.data[0]))\n",
    "\n",
    "        # Save samples of real and fake images every 500 iterations\n",
    "        if gen_iterations % 500 == 0:\n",
    "            real = real.mul(0.5).add(0.5)\n",
    "            vutils.save_image(real, '{0}/real_samples.png'.format(opt.experiment))\n",
    "            fake = netG(Variable(fixed_noise, volatile=True))\n",
    "            fake = F.interpolate(fake, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "            fake.data = fake.data.mul(0.5).add(0.5)\n",
    "            vutils.save_image(fake.data, '{0}/fake_samples_{1}.png'.format(opt.experiment, gen_iterations))\n",
    "\n",
    "    # Checkpointing: Save model weights every 1000 epochs\n",
    "    if epoch % 1000 == 0:   \n",
    "        torch.save(netG.state_dict(), '{0}/netG_epoch_{1}.pth'.format(opt.experiment, epoch))\n",
    "        torch.save(netD.state_dict(), '{0}/netD_epoch_{1}.pth'.format(opt.experiment, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512f088-a622-4d89-9f15-afc100186c01",
   "metadata": {},
   "source": [
    "### GAN outputs \n",
    "* The fake images getting slightly better each iterations as you can see below "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a90d1-307d-4aa1-afb4-6ab66be690e6",
   "metadata": {},
   "source": [
    "### Real Sample :\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/prachuryanath/WBC-NCA---Reproduction/refs/heads/main/images/real_samples.png\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed3c8c-bef4-477d-91b9-331a6a4f0395",
   "metadata": {},
   "source": [
    "### Fake sample after 250 iterations\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/prachuryanath/WBC-NCA---Reproduction/refs/heads/main/images/fake_samples_250.png\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3d10b-eecc-4c68-9543-52da187ef057",
   "metadata": {},
   "source": [
    "### Fake sample after 24500 iterations\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/prachuryanath/WBC-NCA---Reproduction/refs/heads/main/images/fake_samples_24500.png\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79cb15-c600-4777-ab1c-8a79a29f37f4",
   "metadata": {},
   "source": [
    "# Segmentation Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49ba093d-938b-46ae-9b9d-dab83d852a65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from semi.code.data.build_dataset import build_dataset\n",
    "from semi.code.models.build_model import build_model\n",
    "from semi.code.models.dc_gan import DCGAN_D\n",
    "from semi.code.utils.evaluate import evaluate\n",
    "from semi.code.utils.loss import BceDiceLoss\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4228237-1706-478b-a390-d90b9c99aa22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace(GPUs='0,1', root='', dataset='tn3k', ratio=2, manner='semi', mode='train', nEpoch=200, batch_size=32, num_workers=2, load_ckpt='best', model='MyModel', expID=3, ckpt_name='tn3k_1', lr=0.001, power=0.9, betas=[0.9, 0.999], weight_decay='1e-5', eps='1e-8', mt=0.9, nclasses=1, band=3)\n"
     ]
    }
   ],
   "source": [
    "# Load config file\n",
    "with open(\"config_model.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "from types import SimpleNamespace\n",
    "\n",
    "args = SimpleNamespace(**config)\n",
    "print(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6722c362-ab71-498e-b91e-e51027e04722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to calculate Deep Supervised Segmentation Loss (BCE + Dice)\n",
    "def DeepSupSeg(pred, gt):\n",
    "    criterion = BceDiceLoss()\n",
    "    loss = criterion(pred, gt)\n",
    "    return loss\n",
    "\n",
    "# Function to calculate learning rate based on polynomial decay\n",
    "def lr_poly(base_lr, iter, max_iter, power):\n",
    "    return base_lr * ((1-float(iter)/max_iter)**power)\n",
    "\n",
    "# Function to adjust the learning rate during training using lr_poly function\n",
    "def adjust_lr_rate(argsimizer, iter, total_batch):\n",
    "    lr = lr_poly(args.lr, iter, args.nEpoch*total_batch, args.power)\n",
    "    argsimizer.param_groups[0]['lr'] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b839cc-32b0-4e84-8870-5c311e61e92d",
   "metadata": {},
   "source": [
    "## Training the Segmentation Network without GAN weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89fab4f4-ef1f-4c3c-b1ea-882e928ebce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function that loads data, initializes model, and performs training loop\n",
    "def train():\n",
    "    \"\"\"load data\"\"\"\n",
    "    train_l_data, _ , valid_data = build_dataset(args)\n",
    "    train_l_dataloader = DataLoader(train_l_data, args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "    valid_sign = False\n",
    "    if valid_data is not None:\n",
    "        valid_sign = True\n",
    "        valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=False, num_workers=args.num_workers)\n",
    "        val_total_batch = int(len(valid_data) / 1)\n",
    "    \n",
    "    \"\"\"Initialize model and optimizer\"\"\"\n",
    "    model = build_model(args)\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # Using Stochastic Gradient Descent (SGD) optimizer\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.mt, weight_decay=args.weight_decay)\n",
    "\n",
    "    # train\n",
    "    print('\\n---------------------------------')\n",
    "    print('Start training')\n",
    "    print(\"No of cuda devices :\", torch.cuda.device_count())\n",
    "    print('---------------------------------\\n')\n",
    "\n",
    "    F1_best, F1_second_best, F1_third_best = 0, 0, 0\n",
    "    best = 0\n",
    "    for epoch in range(args.nEpoch):\n",
    "\n",
    "        model.train() # Set model to training mode\n",
    "\n",
    "      \n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        total_batch = math.ceil(len(train_l_data) / args.batch_size)\n",
    "        bar = tqdm(enumerate(train_l_dataloader), total=total_batch)\n",
    "        for batch_id, data_l in bar:\n",
    "            itr = total_batch * epoch + batch_id\n",
    "            img, gt = data_l['image'], data_l['label']\n",
    "            if torch.cuda.is_available():\n",
    "                img = img.cuda()\n",
    "                gt = gt.cuda()\n",
    "            optim.zero_grad()\n",
    "            mask = model(img)\n",
    "            loss = DeepSupSeg(mask, gt) \n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            adjust_lr_rate(optim, itr, total_batch)\n",
    "            \n",
    "        # Validation step if validation data is provided\n",
    "        if valid_sign:\n",
    "            recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice, list_name, list_point = evaluate(model, valid_dataloader, val_total_batch)\n",
    "\n",
    "            print(\"Valid Result:\")\n",
    "            print('recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f' \\\n",
    "                % (recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice))\n",
    "\n",
    "            # Track and save best model based on dice score\n",
    "            if dice > best:\n",
    "                best = dice\n",
    "            print(\"Best Dice:: \", best)\n",
    "\n",
    "            # Save model checkpoints based on F1 score performance\n",
    "            if (F1 > F1_best):\n",
    "                F1_best = F1\n",
    "                torch.save(model.state_dict(), args.root + \"/semi/checkpoint/\" + args.ckpt_name + \"/best.pth\")\n",
    "            elif(F1 > F1_second_best):\n",
    "                F1_second_best = F1\n",
    "                torch.save(model.state_dict(), args.root + \"/semi/checkpoint/\" + args.ckpt_name + \"/second_best.pth\")\n",
    "            elif(F1 > F1_third_best):\n",
    "                F1_third_best = F1\n",
    "                torch.save(model.state_dict(), args.root + \"/semi/checkpoint/\" + args.ckpt_name + \"/third_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed0ccb-6818-4deb-b994-6f386544316b",
   "metadata": {},
   "source": [
    "## Training Segmentation Network with DSR (GAN) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab57b2-6989-482c-bc4d-9ef2a896d5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to train the model with both labeled and unlabeled data using GAN model\n",
    "def train_semi():\n",
    "    # Load the dataset (labeled, unlabeled, and validation data)\n",
    "    train_l_data, train_u_data, valid_data = build_dataset(args)\n",
    "    train_l_dataloader = DataLoader(train_l_data, args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "    train_u_dataloader = DataLoader(train_u_data, args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
    "    valid_sign = False\n",
    "    if valid_data is not None:\n",
    "        valid_sign = True\n",
    "        valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=False, num_workers=args.num_workers)\n",
    "        val_total_batch = int(len(valid_data) / 1)\n",
    "        \n",
    "    # Load the model\n",
    "    model = build_model(args)\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    \n",
    "    # Load the discriminator model for the GAN\n",
    "    netD = DCGAN_D(64, 100, 1, 64, 1, 0)\n",
    "    netD = nn.DataParallel(netD)\n",
    "    netD.cuda()\n",
    "    \n",
    "    # Load pre-trained weights for the discriminator\n",
    "    netD_weight = torch.load(\"GAN/result/netD_epoch_5000.pth\")\n",
    "    netD.load_state_dict(netD_weight)\n",
    "    netD.eval()\n",
    "    \n",
    "    # Initialize the optimizer for the model\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.mt, weight_decay=args.weight_decay)\n",
    "\n",
    "    # train\n",
    "    print('\\n---------------------------------')\n",
    "    print('Start training_semi')\n",
    "    print('---------------------------------\\n')\n",
    "    F1_best, F1_second_best, F1_third_best = 0, 0, 0\n",
    "    best = 0\n",
    "    for epoch in range(args.nEpoch):\n",
    "        model.train()\n",
    "        print(\"Epoch: {}\".format(epoch))\n",
    "        loader = iter(zip(cycle(train_l_dataloader), train_u_dataloader))\n",
    "        bar = tqdm(range(len(train_u_dataloader)))\n",
    "        \n",
    "        # Iterate through the training batches\n",
    "        for batch_id in bar:\n",
    "            data_l, data_u = next(loader)\n",
    "            total_batch = len(train_u_dataloader)\n",
    "            itr = total_batch * epoch + batch_id\n",
    "            img_l, gt = data_l['image'], data_l['label']\n",
    "            img_u = data_u\n",
    "            if torch.cuda.is_available():\n",
    "                img_l = img_l.cuda()\n",
    "                gt = gt.cuda()\n",
    "                img_u = img_u.cuda()\n",
    "            optim.zero_grad()\n",
    "\n",
    "            # Forward pass for labeled data\n",
    "            pred_l = model(img_l)\n",
    "            mask = pred_l[0]\n",
    "            loss_l_seg = DeepSupSeg(mask, gt)\n",
    "            loss_l = loss_l_seg\n",
    "            \n",
    "            # Forward pass for unlabeled data\n",
    "            pred_u = model(img_u)\n",
    "            _, predboud, inpimg2, inpimg3, inpimg4, inpimg5, mask_boud = pred_u\n",
    "            loss_u_seg = DeepSupSeg(predboud, mask_boud)\n",
    "            \n",
    "            # Apply GAN loss to unlabeled data\n",
    "            shape_u_1 = F.interpolate(predboud, size = (64, 64), mode = 'bilinear', align_corners = False)\n",
    "            shape_u_2 = F.interpolate(inpimg2, size = (64, 64), mode = 'bilinear', align_corners = False)\n",
    "            shape_u_3 = F.interpolate(inpimg3, size = (64, 64), mode = 'bilinear', align_corners = False)\n",
    "            shape_u_4 = F.interpolate(inpimg4, size = (64, 64), mode = 'bilinear', align_corners = False)\n",
    "            shape_u_5 = F.interpolate(inpimg5, size = (64, 64), mode = 'bilinear', align_corners = False)\n",
    "            loss_u_shape = (netD(shape_u_1) + netD(shape_u_2) + netD(shape_u_3) + netD(shape_u_4) + netD(shape_u_5)) / 5\n",
    "            loss_u = loss_u_seg + 0.1 * loss_u_shape\n",
    "            \n",
    "            # Total loss combines the losses from labeled and unlabeled data\n",
    "            loss = 2 * loss_l + loss_u\n",
    "            loss.sum().backward()\n",
    "            optim.step()\n",
    "            \n",
    "            # Adjust the learning rate\n",
    "            adjust_lr_rate(optim, itr, total_batch)\n",
    "        model.eval()\n",
    "        \n",
    "        # If validation data is available, evaluate the model after each epoch\n",
    "        if valid_sign:\n",
    "            recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice, list_name, list_point = evaluate(model, valid_dataloader, val_total_batch)\n",
    "\n",
    "            print(\"Valid Result:\")\n",
    "            print('recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f' \\\n",
    "                % (recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean,dice))\n",
    "            \n",
    "            # Save best models based on F1 score and dice metric            \n",
    "            if dice > best:\n",
    "                best = dice\n",
    "            print(\"Best Dice:: \", best)\n",
    "\n",
    "            if (F1 > F1_best):\n",
    "                F1_best = F1\n",
    "                torch.save(model.state_dict(), args.root + \"/semi/checkpoint/\" + args.ckpt_name + \"/best.pth\")\n",
    "            elif(F1 > F1_second_best):\n",
    "                F1_second_best = F1\n",
    "                torch.save(model.state_dict(), args.root + \"/semi/checkpoint/\" + args.ckpt_name + \"/second_best.pth\")\n",
    "            elif(F1 > F1_third_best):\n",
    "                F1_third_best = F1\n",
    "                torch.save(model.state_dict(), args.root + \"/semi/checkpoint/\" + args.ckpt_name + \"/third_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39437b9-6e32-4466-a83e-e77d67693eff",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1e8c9bb-a5ec-44b4-b789-8f0d0c6130d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to evaluate the model on the test dataset.\n",
    "def test():\n",
    "  \n",
    "    print('loading data......')\n",
    "    test_data = build_dataset(args)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False, num_workers=args.num_workers)\n",
    "    total_batch = int(len(test_data) / 1)\\\n",
    "    \n",
    "    model = build_model(args)\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate the model on the test dataset\n",
    "    recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean, dice, list_name, list_point = evaluate(model, test_dataloader, total_batch)\n",
    "    \n",
    "    print(\"Test Result:\")\n",
    "    print('recall: %.4f, specificity: %.4f, precision: %.4f, F1: %.4f, F2: %.4f, ACC_overall: %.4f, IoU_poly: %.4f, IoU_bg: %.4f, IoU_mean: %.4f, dice: %.4f' \\\n",
    "                % (recall, specificity, precision, F1, F2, ACC_overall, IoU_poly, IoU_bg, IoU_mean,dice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31aa242d-ac3b-40ef-9153-958fff2628fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30d3da88-a272-45a2-bbf2-37aea70ee545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint directory if it doesn't exist\n",
    "checkpoint_name = os.path.join(args.root, 'semi/checkpoint/' + args.ckpt_name)\n",
    "if not os.path.exists(checkpoint_name):\n",
    "    os.makedirs(checkpoint_name)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945bc0d-fc61-461a-b595-4bc7b22dba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on the mode: full training, semi-supervised training, or testing\n",
    "if args.manner == 'full':\n",
    "    print('---{}-Seg Train---'.format(args.dataset))\n",
    "    train()\n",
    "elif args.manner =='semi':\n",
    "    print('---{}-seg Semi-Train--'.format(args.dataset))\n",
    "    train_semi()\n",
    "elif args.manner == 'test':\n",
    "    print('---{}-Seg Test---'.format(args.dataset))\n",
    "    test()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd75cf7-b957-4fe4-a4e2-95c46ea57066",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "* As shown in the following images, the results obtained from our complete model are presented. These results are found to be quite similar to the results reported in the original paper, specifically when applied to a subset of 1/8 of the images used in our experiment.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/prachuryanath/WBC-NCA---Reproduction/refs/heads/main/images/Screenshot%202025-02-21%20001220.jpg\" width=\"600\" />\n",
    "</div>\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"https://raw.githubusercontent.com/prachuryanath/WBC-NCA---Reproduction/refs/heads/main/images/Screenshot%202025-02-21%20002126.jpg\" width=\"400\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eae98d2-d90d-4884-8967-798ea52134e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Some labels and model outputs\n",
    "\n",
    "#### First segmentation\n",
    "\n",
    "* Real mask :\n",
    "<div>\n",
    "<img src=\"https://github.com/prachuryanath/WBC-NCA---Reproduction/blob/main/images/1651.jpg?raw=true\" width=\"300\" />\n",
    "</div>\n",
    "\n",
    "* Model Output Mask :\n",
    "<div>\n",
    "<img src=\"https://github.com/prachuryanath/WBC-NCA---Reproduction/blob/main/images/1651.png?raw=true\" width=\"300\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd3748-8f94-4b63-8f4f-07223ce812a8",
   "metadata": {},
   "source": [
    "#### Second segmentation\n",
    "\n",
    "* Real mask :\n",
    "<div>\n",
    "<img src=\"https://github.com/prachuryanath/WBC-NCA---Reproduction/blob/main/images/2150.jpg?raw=true\" width=\"300\" />\n",
    "</div>\n",
    "\n",
    "* Model Output Mask :\n",
    "\n",
    "<div>\n",
    "<img src=\"https://github.com/prachuryanath/WBC-NCA---Reproduction/blob/main/images/2150.png?raw=true\" width=\"300\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c7bc75-026f-43bc-a942-11b7db82d59e",
   "metadata": {},
   "source": [
    "#### Third segmentation\n",
    "\n",
    "* Real Mask :\n",
    "<div>\n",
    "<img src=\"https://github.com/prachuryanath/WBC-NCA---Reproduction/blob/main/images/1671.jpg?raw=true\" width=\"300\" />\n",
    "</div>\n",
    "\n",
    "* Model Output Mask :\n",
    "<div>\n",
    "<img src=\"https://github.com/prachuryanath/WBC-NCA---Reproduction/blob/main/images/1671.png?raw=true\" width=\"300\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91345682-8823-42b9-aab3-727a0dc855de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Challenges\n",
    "\n",
    "1. Insufficient Code Comments: The repository lacks comments, requiring additions for clarity.\n",
    "2. Disorganized Repository: The folder structure and setup are unorganized, needing restructuring and configuration files.\n",
    "3. Required Code Modifications: Some moderate changes are necessary to align the code with the paper’s results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27556a6d-bc6b-4eb9-ad51-cb6b83aebe17",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Reproducing the paper's findings revealed some significant difficulties, especially with structuring the code and including the required explanations in the comments. This reproduction is classified as Level 3 because while the paper and repository provide most of the necessary setup, the code lacks sufficient comments, and the repository does not have an ideal structure. This requires moderate changes to properly reproduce even one figure from the paper, including restructuring the code, adding comments, and ensuring a proper setup for smooth execution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
